{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GonzaloLaChica1/Bias_Model/blob/main/BiasModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_s_y-q2_bC6",
        "outputId": "184e9f15-5d75-4200-9612-6035b5272660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set visualization style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Bias/raw_data\"\n",
        "\n",
        "compas_data = \"\"\n",
        "\n",
        "\n",
        "for root, dirs, files in os.walk(path):\n",
        "  for f in files: # Iterate through each individual filename (string)\n",
        "      adult_test = os.path.join(root,f)\n",
        "      if \"compas-scores-two-years.csv\" in f:\n",
        "        compas_data = os.path.join(root,f)\n",
        "\n",
        "\n",
        "\n",
        "print(compas_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGmKGdvZE1kY",
        "outputId": "568d51a9-d3cb-4ccd-e1e0-228ce5e85d5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Bias/raw_data/compas-scores-two-years.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(compas_data)\n",
        "# df.head()\n",
        "features = ['age', 'priors_count.1', 'v_decile_score']\n",
        "target = 'two_year_recid'\n",
        "protected_attr = 'race'\n",
        "\n",
        "df_filtered = df[df['race'].isin(['African-American', 'Caucasian'])].copy() # take all columns and rows from df dataframe where isin() retrurn true\n",
        "df_filtered = df_filtered.dropna(subset=features + [target, protected_attr])\n",
        "\n",
        "\n",
        "\n",
        "# df_filtered = df_filtered.rename(columns={'priors_count.1':'priors_count', 'v_decile_score': 'decile_score' })\n",
        "df_filtered['race_binary'] = (df_filtered['race'] == 'African-American').astype(int)\n",
        "print(f\"total records: {len(df_filtered)}\")\n",
        "print(f\"African-America: {(df_filtered['race']=='African-American').sum()}\")\n",
        "print(f\"Caucasina: {(df['race'] == 'Caucasian').sum()}\")\n",
        "df_filtered.head()\n",
        "\n",
        "df_filtered[['name', 'race', 'priors_count', 'decile_score', 'race_binary', 'two_year_recid']].head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "zRhooklbc_RZ",
        "outputId": "667cfd3f-dd65-48ec-f600-201994a7f262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total records: 6150\n",
            "African-America: 3696\n",
            "Caucasina: 2454\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                name              race  priors_count  decile_score  \\\n",
              "1        kevon dixon  African-American             0             3   \n",
              "2           ed philo  African-American             4             4   \n",
              "3        marcu brown  African-American             1             8   \n",
              "6      edward riddle         Caucasian            14             6   \n",
              "8   elizabeth thieme         Caucasian             0             1   \n",
              "9          bo bradac         Caucasian             1             3   \n",
              "10    benjamin franc         Caucasian             0             4   \n",
              "11    ellyaher lanza  African-American             3             6   \n",
              "12   kortney coleman         Caucasian             0             1   \n",
              "13      jarrod turbe  African-American             0             4   \n",
              "\n",
              "    race_binary  two_year_recid  \n",
              "1             1               1  \n",
              "2             1               1  \n",
              "3             1               0  \n",
              "6             0               1  \n",
              "8             0               0  \n",
              "9             0               1  \n",
              "10            0               0  \n",
              "11            1               1  \n",
              "12            0               0  \n",
              "13            1               0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dedbef73-58a6-4443-b438-ddadaed314f8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>race</th>\n",
              "      <th>priors_count</th>\n",
              "      <th>decile_score</th>\n",
              "      <th>race_binary</th>\n",
              "      <th>two_year_recid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kevon dixon</td>\n",
              "      <td>African-American</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ed philo</td>\n",
              "      <td>African-American</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>marcu brown</td>\n",
              "      <td>African-American</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>edward riddle</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>elizabeth thieme</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>bo bradac</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>benjamin franc</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ellyaher lanza</td>\n",
              "      <td>African-American</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>kortney coleman</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>jarrod turbe</td>\n",
              "      <td>African-American</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dedbef73-58a6-4443-b438-ddadaed314f8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dedbef73-58a6-4443-b438-ddadaed314f8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dedbef73-58a6-4443-b438-ddadaed314f8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d688b38b-8383-416f-9017-33bd8f44a43d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d688b38b-8383-416f-9017-33bd8f44a43d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d688b38b-8383-416f-9017-33bd8f44a43d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_filtered[['name', 'race', 'priors_count', 'decile_score', 'race_binary', 'two_year_recid']]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"kortney coleman\",\n          \"ed philo\",\n          \"bo bradac\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"race\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Caucasian\",\n          \"African-American\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"priors_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 14,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"decile_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 8,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"race_binary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"two_year_recid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_filtered[features]\n",
        "y = df_filtered[target]\n",
        "race = df_filtered['race_binary']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu1Fogvxqkb6",
        "outputId": "dee83d4f-3e66-43e2-e2fb-97e5a60170bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 67.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate fairness matrics\n",
        "\n"
      ],
      "metadata": {
        "id": "28ognCdiz92x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set visualization style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# SECTION 2: DATA LOADING\n",
        "\n",
        "def load_compas_data(filepath=compas_data):\n",
        "    \"\"\"Load and prepare COMPAS dataset\"\"\"\n",
        "    print(\"\\nüìä Loading COMPAS Dataset...\")\n",
        "\n",
        "    df = pd.read_csv(filepath)\n",
        "\n",
        "    print(f\"‚úÖ Loaded {len(df):,} records\")\n",
        "    print(f\"   Columns: {len(df.columns)}\")\n",
        "    print(f\"   Memory: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def load_adult_data(train_path=adult_data,\n",
        "                    test_path=adult_test):\n",
        "    \"\"\"Load and prepare UCI Adult dataset\"\"\"\n",
        "    print(\"\\nüìä Loading UCI Adult Dataset...\")\n",
        "\n",
        "    # Column names\n",
        "    columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
        "               'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "               'capital-gain', 'capital-loss', 'hours-per-week',\n",
        "               'native-country', 'income']\n",
        "\n",
        "    # Load train and test\n",
        "    df_train = pd.read_csv(train_path, names=columns,\n",
        "                          skipinitialspace=True, na_values='?')\n",
        "    df_test = pd.read_csv(test_path, names=columns,\n",
        "                         skipinitialspace=True, skiprows=1, na_values='?')\n",
        "\n",
        "    # Combine\n",
        "    df = pd.concat([df_train, df_test], ignore_index=True)\n",
        "\n",
        "    print(f\"‚úÖ Loaded {len(df):,} records\")\n",
        "    print(f\"   Train: {len(df_train):,} | Test: {len(df_test):,}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def load_hmda_data(filepath=hmda_data,\n",
        "                   sample_size=100000):\n",
        "    \"\"\"Load and prepare HMDA dataset\"\"\"\n",
        "    print(\"\\nüìä Loading HMDA Dataset...\")\n",
        "\n",
        "    # Read sample (HMDA is large)\n",
        "    df = pd.read_csv(filepath, nrows=sample_size)\n",
        "\n",
        "    print(f\"‚úÖ Loaded {len(df):,} records\")\n",
        "    print(f\"   Columns: {len(df.columns)}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# SECTION 3: EXPLORATORY DATA ANALYSIS\n",
        "\n",
        "\n",
        "def explore_dataset(df, dataset_name, target_col, protected_attrs):\n",
        "    \"\"\"Comprehensive EDA for any dataset\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"EXPLORATORY ANALYSIS: {dataset_name}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Basic info\n",
        "    print(f\"\\nüìã Dataset Shape: {df.shape}\")\n",
        "    print(f\"\\nüìã Data Types:\")\n",
        "    print(df.dtypes.value_counts())\n",
        "\n",
        "    # Missing values\n",
        "    print(f\"\\n‚ö†Ô∏è  Missing Values:\")\n",
        "    missing = df.isnull().sum()\n",
        "    missing_pct = (missing / len(df) * 100).round(2)\n",
        "    missing_df = pd.DataFrame({\n",
        "        'Missing': missing[missing > 0],\n",
        "        'Percent': missing_pct[missing > 0]\n",
        "    }).sort_values('Percent', ascending=False)\n",
        "    if len(missing_df) > 0:\n",
        "        print(missing_df.head(10))\n",
        "    else:\n",
        "        print(\"‚úÖ No missing values!\")\n",
        "\n",
        "    # Target distribution\n",
        "    print(f\"\\nüéØ Target Variable: {target_col}\")\n",
        "    print(df[target_col].value_counts())\n",
        "    print(f\"\\nTarget Distribution:\")\n",
        "    print(df[target_col].value_counts(normalize=True).apply(lambda x: f\"{x*100:.2f}%\"))\n",
        "\n",
        "    # Protected attributes analysis\n",
        "    print(f\"\\nüîí Protected Attributes Analysis:\")\n",
        "    for attr in protected_attrs:\n",
        "        if attr in df.columns:\n",
        "            print(f\"\\n{attr.upper()}:\")\n",
        "            print(df[attr].value_counts().head(10))\n",
        "            print(f\"Unique values: {df[attr].nunique()}\")\n",
        "\n",
        "    # Visualizations\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle(f'{dataset_name} - Overview', fontsize=16)\n",
        "\n",
        "    # Target distribution\n",
        "    df[target_col].value_counts().plot(kind='bar', ax=axes[0, 0], color='steelblue')\n",
        "    axes[0, 0].set_title('Target Distribution')\n",
        "    axes[0, 0].set_xlabel(target_col)\n",
        "    axes[0, 0].set_ylabel('Count')\n",
        "\n",
        "    # Protected attribute distributions\n",
        "    if len(protected_attrs) >= 1 and protected_attrs[0] in df.columns:\n",
        "        df[protected_attrs[0]].value_counts().head(10).plot(\n",
        "            kind='bar', ax=axes[0, 1], color='coral')\n",
        "        axes[0, 1].set_title(f'{protected_attrs[0]} Distribution')\n",
        "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    if len(protected_attrs) >= 2 and protected_attrs[1] in df.columns:\n",
        "        df[protected_attrs[1]].value_counts().plot(\n",
        "            kind='bar', ax=axes[1, 0], color='lightgreen')\n",
        "        axes[1, 0].set_title(f'{protected_attrs[1]} Distribution')\n",
        "\n",
        "    # Missing data heatmap (if any)\n",
        "    if missing.sum() > 0:\n",
        "        sns.heatmap(df.isnull(), yticklabels=False, cbar=True,\n",
        "                   cmap='viridis', ax=axes[1, 1])\n",
        "        axes[1, 1].set_title('Missing Data Pattern')\n",
        "    else:\n",
        "        axes[1, 1].text(0.5, 0.5, 'No Missing Data',\n",
        "                       ha='center', va='center', fontsize=14)\n",
        "        axes[1, 1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'outputs/{dataset_name}_eda.png', dpi=300, bbox_inches='tight')\n",
        "    print(f\"\\nüìä Visualization saved: outputs/{dataset_name}_eda.png\")\n",
        "    plt.savefig(f'/content/drive/MyDrive/Bias/outputs/{dataset_name}_eda.png')\n",
        "    plt.show()\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# SECTION 4: DATA PREPROCESSING\n",
        "\n",
        "\n",
        "def preprocess_compas(df):\n",
        "    \"\"\"Clean and prepare COMPAS data\"\"\"\n",
        "    print(\"\\nüîß Preprocessing COMPAS...\")\n",
        "\n",
        "    # Select relevant columns\n",
        "    cols = ['age', 'c_charge_degree', 'race', 'age_cat', 'score_text',\n",
        "            'sex', 'priors_count', 'days_b_screening_arrest',\n",
        "            'decile_score', 'is_recid', 'two_year_recid',\n",
        "            'c_jail_in', 'c_jail_out']\n",
        "\n",
        "    df = df[cols].copy()\n",
        "\n",
        "    # Filter data (standard COMPAS filtering)\n",
        "    df = df[df['days_b_screening_arrest'] <= 30]\n",
        "    df = df[df['days_b_screening_arrest'] >= -30]\n",
        "    df = df[df['is_recid'] != -1]\n",
        "    df = df[df['c_charge_degree'] != \"O\"]\n",
        "    df = df[df['score_text'] != 'N/A']\n",
        "\n",
        "    # Create target\n",
        "    df['target'] = df['two_year_recid']\n",
        "\n",
        "    # Encode protected attributes\n",
        "    df['race_binary'] = df['race'].apply(\n",
        "        lambda x: 1 if x == 'Caucasian' else 0)\n",
        "    df['sex_binary'] = df['sex'].apply(\n",
        "        lambda x: 1 if x == 'Male' else 0)\n",
        "\n",
        "    # Feature engineering\n",
        "    df['age_squared'] = df['age'] ** 2\n",
        "    df['priors_squared'] = df['priors_count'] ** 2\n",
        "\n",
        "    print(f\"‚úÖ Final shape: {df.shape}\")\n",
        "    print(f\"   Recidivism rate: {df['target'].mean()*100:.2f}%\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def preprocess_adult(df):\n",
        "    \"\"\"Clean and prepare UCI Adult data\"\"\"\n",
        "    print(\"\\nüîß Preprocessing UCI Adult...\")\n",
        "\n",
        "    # Remove missing values\n",
        "    df = df.dropna()\n",
        "\n",
        "    # Create binary target\n",
        "    df['target'] = df['income'].apply(lambda x: 1 if '>50K' in x else 0)\n",
        "\n",
        "    # Encode protected attributes\n",
        "    df['race_binary'] = df['race'].apply(\n",
        "        lambda x: 1 if x == 'White' else 0)\n",
        "    df['sex_binary'] = df['sex'].apply(\n",
        "        lambda x: 1 if x == 'Male' else 0)\n",
        "\n",
        "    # Encode categorical variables\n",
        "    categorical_cols = ['workclass', 'education', 'marital-status',\n",
        "                       'occupation', 'relationship', 'native-country']\n",
        "\n",
        "    le_dict = {}\n",
        "    for col in categorical_cols:\n",
        "        le = LabelEncoder()\n",
        "        df[col + '_encoded'] = le.fit_transform(df[col])\n",
        "        le_dict[col] = le\n",
        "\n",
        "    print(f\"‚úÖ Final shape: {df.shape}\")\n",
        "    print(f\"   High income rate: {df['target'].mean()*100:.2f}%\")\n",
        "\n",
        "    return df, le_dict\n",
        "\n",
        "def preprocess_hmda(df):\n",
        "    \"\"\"Clean and prepare HMDA data\"\"\"\n",
        "    print(\"\\nüîß Preprocessing HMDA...\")\n",
        "\n",
        "    # Filter for originated or denied loans\n",
        "    df = df[df['action_taken'].isin([1, 3])].copy()\n",
        "\n",
        "    # Create target (1 = approved, 0 = denied)\n",
        "    df['target'] = df['action_taken'].apply(lambda x: 1 if x == 1 else 0)\n",
        "\n",
        "    # Encode protected attributes\n",
        "    if 'derived_race' in df.columns:\n",
        "        df['race_binary'] = df['derived_race'].apply(\n",
        "            lambda x: 1 if x == 'White' else 0)\n",
        "\n",
        "    if 'derived_sex' in df.columns:\n",
        "        df['sex_binary'] = df['derived_sex'].apply(\n",
        "            lambda x: 1 if x == 'Male' else 0)\n",
        "\n",
        "    # Select numeric features\n",
        "    numeric_features = ['loan_amount', 'income', 'property_value',\n",
        "                       'debt_to_income_ratio', 'applicant_age']\n",
        "\n",
        "    # Keep only available features\n",
        "    numeric_features = [f for f in numeric_features if f in df.columns]\n",
        "\n",
        "    print(f\"‚úÖ Final shape: {df.shape}\")\n",
        "    print(f\"   Approval rate: {df['target'].mean()*100:.2f}%\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# SECTION 5: BASELINE MODEL TRAINING\n",
        "\n",
        "\n",
        "def prepare_train_test(df, feature_cols, target_col='target',\n",
        "                       test_size=0.2, random_state=42):\n",
        "    \"\"\"Split data into train/test sets\"\"\"\n",
        "\n",
        "    X = df[feature_cols]\n",
        "    y = df[target_col]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
        "\n",
        "    print(f\"\\nüìä Train/Test Split:\")\n",
        "    print(f\"   Training: {len(X_train):,} samples\")\n",
        "    print(f\"   Testing: {len(X_test):,} samples\")\n",
        "    print(f\"   Positive rate (train): {y_train.mean()*100:.2f}%\")\n",
        "    print(f\"   Positive rate (test): {y_test.mean()*100:.2f}%\")\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def train_baseline_models(X_train, X_test, y_train, y_test, dataset_name):\n",
        "    \"\"\"Train Logistic Regression, Random Forest, and XGBoost\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"TRAINING BASELINE MODELS: {dataset_name}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # 1. Logistic Regression\n",
        "    print(\"\\nüîÑ Training Logistic Regression...\")\n",
        "    lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "    lr.fit(X_train, y_train)\n",
        "    lr_pred = lr.predict(X_test)\n",
        "    lr_proba = lr.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    results['Logistic Regression'] = {\n",
        "        'model': lr,\n",
        "        'predictions': lr_pred,\n",
        "        'probabilities': lr_proba,\n",
        "        'accuracy': accuracy_score(y_test, lr_pred),\n",
        "        'precision': precision_score(y_test, lr_pred),\n",
        "        'recall': recall_score(y_test, lr_pred),\n",
        "        'f1': f1_score(y_test, lr_pred),\n",
        "        'auc': roc_auc_score(y_test, lr_proba)\n",
        "    }\n",
        "    print(f\"‚úÖ Accuracy: {results['Logistic Regression']['accuracy']:.4f}\")\n",
        "\n",
        "    # 2. Random Forest\n",
        "    print(\"\\nüîÑ Training Random Forest...\")\n",
        "    rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "    rf.fit(X_train, y_train)\n",
        "    rf_pred = rf.predict(X_test)\n",
        "    rf_proba = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    results['Random Forest'] = {\n",
        "        'model': rf,\n",
        "        'predictions': rf_pred,\n",
        "        'probabilities': rf_proba,\n",
        "        'accuracy': accuracy_score(y_test, rf_pred),\n",
        "        'precision': precision_score(y_test, rf_pred),\n",
        "        'recall': recall_score(y_test, rf_pred),\n",
        "        'f1': f1_score(y_test, rf_pred),\n",
        "        'auc': roc_auc_score(y_test, rf_proba)\n",
        "    }\n",
        "    print(f\"‚úÖ Accuracy: {results['Random Forest']['accuracy']:.4f}\")\n",
        "\n",
        "    # 3. XGBoost\n",
        "    print(\"\\nüîÑ Training XGBoost...\")\n",
        "    xgb_model = xgb.XGBClassifier(n_estimators=100, random_state=42,\n",
        "                                  use_label_encoder=False, eval_metric='logloss')\n",
        "    xgb_model.fit(X_train, y_train)\n",
        "    xgb_pred = xgb_model.predict(X_test)\n",
        "    xgb_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    results['XGBoost'] = {\n",
        "        'model': xgb_model,\n",
        "        'predictions': xgb_pred,\n",
        "        'probabilities': xgb_proba,\n",
        "        'accuracy': accuracy_score(y_test, xgb_pred),\n",
        "        'precision': precision_score(y_test, xgb_pred),\n",
        "        'recall': recall_score(y_test, xgb_pred),\n",
        "        'f1': f1_score(y_test, xgb_pred),\n",
        "        'auc': roc_auc_score(y_test, xgb_proba)\n",
        "    }\n",
        "    print(f\"‚úÖ Accuracy: {results['XGBoost']['accuracy']:.4f}\")\n",
        "\n",
        "    # Summary comparison\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"MODEL COMPARISON\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    comparison_df = pd.DataFrame({\n",
        "        'Model': results.keys(),\n",
        "        'Accuracy': [r['accuracy'] for r in results.values()],\n",
        "        'Precision': [r['precision'] for r in results.values()],\n",
        "        'Recall': [r['recall'] for r in results.values()],\n",
        "        'F1-Score': [r['f1'] for r in results.values()],\n",
        "        'AUC-ROC': [r['auc'] for r in results.values()]\n",
        "    })\n",
        "\n",
        "    print(comparison_df.to_string(index=False))\n",
        "\n",
        "    # Visualize comparison\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Metrics comparison\n",
        "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']\n",
        "    x = np.arange(len(metrics))\n",
        "    width = 0.25\n",
        "\n",
        "    for i, (model_name, result) in enumerate(results.items()):\n",
        "        values = [result['accuracy'], result['precision'],\n",
        "                 result['recall'], result['f1'], result['auc']]\n",
        "        axes[0].bar(x + i*width, values, width, label=model_name)\n",
        "\n",
        "    axes[0].set_xlabel('Metrics')\n",
        "    axes[0].set_ylabel('Score')\n",
        "    axes[0].set_title(f'{dataset_name} - Model Performance Comparison')\n",
        "    axes[0].set_xticks(x + width)\n",
        "    axes[0].set_xticklabels(metrics)\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Confusion matrices\n",
        "    for i, (model_name, result) in enumerate(results.items()):\n",
        "        cm = confusion_matrix(y_test, result['predictions'])\n",
        "\n",
        "        if i == 0:\n",
        "            ax = axes[1]\n",
        "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
        "            ax.set_title(f'{model_name}\\nConfusion Matrix')\n",
        "            ax.set_ylabel('True Label')\n",
        "            ax.set_xlabel('Predicted Label')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'outputs/{dataset_name}_baseline_models.png',\n",
        "                dpi=300, bbox_inches='tight')\n",
        "    print(f\"\\nüìä Visualization saved: outputs/{dataset_name}_baseline_models.png\")\n",
        "    plt.savefig(f'/content/drive/MyDrive/Bias/outputs/{dataset_name}_baseline_models.png')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    return results, comparison_df\n",
        "\n",
        "\n",
        "# SECTION 6: INITIAL BIAS CHECK\n",
        "\n",
        "\n",
        "def check_initial_bias(df, predictions, protected_attr, target_col='target'):\n",
        "    \"\"\"Quick bias check across protected attribute\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"INITIAL BIAS CHECK: {protected_attr}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    df_check = df.copy()\n",
        "    df_check['prediction'] = predictions\n",
        "\n",
        "    # Group by protected attribute\n",
        "    groups = df_check[protected_attr].unique()\n",
        "\n",
        "    print(f\"\\nüìä Outcome Rates by {protected_attr}:\")\n",
        "    for group in groups:\n",
        "        group_data = df_check[df_check[protected_attr] == group]\n",
        "\n",
        "        actual_rate = group_data[target_col].mean()\n",
        "        pred_rate = group_data['prediction'].mean()\n",
        "\n",
        "        print(f\"\\n  Group {group}:\")\n",
        "        print(f\"    Sample size: {len(group_data):,}\")\n",
        "        print(f\"    Actual positive rate: {actual_rate*100:.2f}%\")\n",
        "        print(f\"    Predicted positive rate: {pred_rate*100:.2f}%\")\n",
        "\n",
        "    # Calculate disparate impact\n",
        "    if len(groups) == 2:\n",
        "        group0 = df_check[df_check[protected_attr] == groups[0]]\n",
        "        group1 = df_check[df_check[protected_attr] == groups[1]]\n",
        "\n",
        "        rate0 = group0['prediction'].mean()\n",
        "        rate1 = group1['prediction'].mean()\n",
        "\n",
        "        di_ratio = min(rate0, rate1) / max(rate0, rate1)\n",
        "\n",
        "        print(f\"\\n‚öñÔ∏è  Disparate Impact Ratio: {di_ratio:.3f}\")\n",
        "        if di_ratio < 0.8:\n",
        "            print(\"   ‚ö†Ô∏è  WARNING: Below 0.80 threshold (potential discrimination)\")\n",
        "        else:\n",
        "            print(\"   ‚úÖ Above 0.80 threshold\")\n",
        "\n",
        "    # Visualization\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Prediction rates by group\n",
        "    pred_rates = df_check.groupby(protected_attr)['prediction'].mean()\n",
        "    pred_rates.plot(kind='bar', ax=axes[0], color='steelblue')\n",
        "    axes[0].set_title(f'Positive Prediction Rate by {protected_attr}')\n",
        "    axes[0].set_ylabel('Rate')\n",
        "    axes[0].axhline(y=0.8*pred_rates.max(), color='r',\n",
        "                    linestyle='--', label='80% threshold')\n",
        "    axes[0].legend()\n",
        "\n",
        "    # Actual vs predicted by group\n",
        "    comparison = df_check.groupby(protected_attr).agg({\n",
        "        target_col: 'mean',\n",
        "        'prediction': 'mean'\n",
        "    })\n",
        "    comparison.plot(kind='bar', ax=axes[1])\n",
        "    axes[1].set_title(f'Actual vs Predicted Rates by {protected_attr}')\n",
        "    axes[1].set_ylabel('Rate')\n",
        "    axes[1].legend(['Actual', 'Predicted'])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.savefig(f'/content/drive/MyDrive/Bias/outputs/{protected_attr}_bias_check.png',\n",
        "                dpi=300, bbox_inches='tight')\n",
        "\n",
        "\n",
        "# MAIN EXECUTION\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"FEDERAL AI BIAS RESEARCH - WEEK 1\")\n",
        "    print(\"Data Exploration & Baseline Models\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Create output directory\n",
        "    import os\n",
        "    os.makedirs('outputs', exist_ok=True)\n",
        "\n",
        "\n",
        "    # COMPAS DATASET\n",
        "\n",
        "\n",
        "    print(\"\\n\\n\" + \"#\"*70)\n",
        "    print(\"# DATASET 1: COMPAS (Criminal Justice)\")\n",
        "    print(\"#\"*70)\n",
        "\n",
        "    # Load\n",
        "    compas_df = load_compas_data(compas_data)\n",
        "\n",
        "    # Explore\n",
        "    compas_df = explore_dataset(\n",
        "        compas_df,\n",
        "        'COMPAS',\n",
        "        target_col='two_year_recid',\n",
        "        protected_attrs=['race', 'sex', 'age_cat']\n",
        "    )\n",
        "\n",
        "    # Preprocess\n",
        "    compas_clean = preprocess_compas(compas_df)\n",
        "\n",
        "    # Define features\n",
        "    compas_features = ['age', 'priors_count', 'age_squared',\n",
        "                      'priors_squared', 'c_charge_degree']\n",
        "\n",
        "    # Encode categorical\n",
        "    compas_clean['c_charge_degree'] = LabelEncoder().fit_transform(\n",
        "        compas_clean['c_charge_degree'])\n",
        "\n",
        "    # Train/test split\n",
        "    X_train_c, X_test_c, y_train_c, y_test_c = prepare_train_test(\n",
        "        compas_clean, compas_features)\n",
        "\n",
        "    # Train models\n",
        "    compas_results, compas_comparison = train_baseline_models(\n",
        "        X_train_c, X_test_c, y_train_c, y_test_c, 'COMPAS')\n",
        "\n",
        "    # Check bias\n",
        "    check_initial_bias(\n",
        "        compas_clean.loc[X_test_c.index], # Fix: Changed .iloc to .loc\n",
        "        compas_results['XGBoost']['predictions'],\n",
        "        'race_binary',\n",
        "        'target'\n",
        "    )\n",
        "\n",
        "\n",
        "    # UCI ADULT DATASET\n",
        "\n",
        "\n",
        "    print(\"\\n\\n\" + \"#\"*70)\n",
        "    print(\"# DATASET 2: UCI ADULT (Benefits/Economic)\")\n",
        "    print(\"#\"*70)\n",
        "\n",
        "    # Load\n",
        "    adult_df = load_adult_data(\n",
        "        adult_data,\n",
        "        adult_test\n",
        "    )\n",
        "\n",
        "    # Explore\n",
        "    adult_df = explore_dataset(\n",
        "        adult_df,\n",
        "        'UCI_Adult',\n",
        "        target_col='income',\n",
        "        protected_attrs=['race', 'sex', 'age']\n",
        "    )\n",
        "\n",
        "    # Preprocess\n",
        "    adult_clean, adult_encoders = preprocess_adult(adult_df)\n",
        "\n",
        "    # Define features\n",
        "    adult_features = ['age', 'education-num', 'hours-per-week',\n",
        "                     'capital-gain', 'capital-loss',\n",
        "                     'workclass_encoded', 'marital-status_encoded',\n",
        "                     'occupation_encoded', 'relationship_encoded']\n",
        "\n",
        "    # Train/test split\n",
        "    X_train_a, X_test_a, y_train_a, y_test_a = prepare_train_test(\n",
        "        adult_clean, adult_features)\n",
        "\n",
        "    # Train models\n",
        "    adult_results, adult_comparison = train_baseline_models(\n",
        "        X_train_a, X_test_a, y_train_a, y_test_a, 'UCI_Adult')\n",
        "\n",
        "    # Check bias\n",
        "    check_initial_bias(\n",
        "        adult_clean.loc[X_test_a.index], # Fix: Changed .iloc to .loc\n",
        "        adult_results['XGBoost']['predictions'],\n",
        "        'race_binary',\n",
        "        'target'\n",
        "    )\n",
        "\n",
        "\n",
        "    # HMDA DATASET\n",
        "\n",
        "\n",
        "    print(\"\\n\\n\" + \"#\"*70)\n",
        "    print(\"# DATASET 3: HMDA (Lending/Mortgage)\")\n",
        "    print(\"#\"*70)\n",
        "\n",
        "    try:\n",
        "        # Load\n",
        "        hmda_df = load_hmda_data(hmda_data,\n",
        "                                 sample_size=100000)\n",
        "\n",
        "        # Explore\n",
        "        hmda_df = explore_dataset(\n",
        "            hmda_df,\n",
        "            'HMDA',\n",
        "            target_col='action_taken',\n",
        "            protected_attrs=['derived_race', 'derived_sex',\n",
        "                           'derived_ethnicity', 'applicant_age']\n",
        "        )\n",
        "\n",
        "        # Preprocess\n",
        "        hmda_clean = preprocess_hmda(hmda_df)\n",
        "\n",
        "        # Define features (adjust based on available columns)\n",
        "        hmda_features = []\n",
        "\n",
        "        # Add features that exist in the dataset\n",
        "        possible_features = ['loan_amount', 'income', 'property_value',\n",
        "                           'debt_to_income_ratio', 'loan_term',\n",
        "                           'interest_rate', 'rate_spread',\n",
        "                           'loan_to_value_ratio', 'combined_loan_to_value_ratio']\n",
        "\n",
        "        for feat in possible_features:\n",
        "            if feat in hmda_clean.columns:\n",
        "                # Handle missing values\n",
        "                hmda_clean[feat] = hmda_clean[feat].fillna(\n",
        "                    hmda_clean[feat].median())\n",
        "                hmda_features.append(feat)\n",
        "\n",
        "        # Encode categorical features if needed\n",
        "        if 'loan_type' in hmda_clean.columns:\n",
        "            hmda_clean['loan_type_encoded'] = LabelEncoder().fit_transform(\n",
        "                hmda_clean['loan_type'].fillna('Unknown'))\n",
        "            hmda_features.append('loan_type_encoded')\n",
        "\n",
        "        if 'loan_purpose' in hmda_clean.columns:\n",
        "            hmda_clean['loan_purpose_encoded'] = LabelEncoder().fit_transform(\n",
        "                hmda_clean['loan_purpose'].fillna('Unknown'))\n",
        "            hmda_features.append('loan_purpose_encoded')\n",
        "\n",
        "        print(f\"\\nüìã Using {len(hmda_features)} features: {hmda_features}\")\n",
        "\n",
        "        # Drop rows with missing target or features\n",
        "        hmda_clean = hmda_clean.dropna(subset=['target'] + hmda_features)\n",
        "\n",
        "        # Train/test split\n",
        "        X_train_h, X_test_h, y_train_h, y_test_h = prepare_train_test(\n",
        "            hmda_clean, hmda_features)\n",
        "\n",
        "        # Train models\n",
        "        hmda_results, hmda_comparison = train_baseline_models(\n",
        "            X_train_h, X_test_h, y_train_h, y_test_h, 'HMDA')\n",
        "\n",
        "        # Check bias - Race\n",
        "        if 'race_binary' in hmda_clean.columns:\n",
        "            print(\"\\n\" + \"=\"*70)\n",
        "            print(\"BIAS CHECK: RACE\")\n",
        "            print(\"=\"*70)\n",
        "            check_initial_bias(\n",
        "                hmda_clean.loc[X_test_h.index], # Fix: Changed .iloc to .loc\n",
        "                hmda_results['XGBoost']['predictions'],\n",
        "                'race_binary',\n",
        "                'target'\n",
        "            )\n",
        "\n",
        "        # Check bias - Gender\n",
        "        if 'sex_binary' in hmda_clean.columns:\n",
        "            print(\"\\n\" + \"=\"*70)\n",
        "            print(\"BIAS CHECK: GENDER\")\n",
        "            print(\"=\"*70)\n",
        "            check_initial_bias(\n",
        "                hmda_clean.loc[X_test_h.index], # Fix: Changed .iloc to .loc\n",
        "                hmda_results['XGBoost']['predictions'],\n",
        "                'sex_binary',\n",
        "                'target'\n",
        "            )\n",
        "\n",
        "        print(\"\\n‚úÖ HMDA analysis complete!\")\n",
        "        hmda_completed = True\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"\\n‚ö†Ô∏è  HMDA file not found. Skipping HMDA analysis.\")\n",
        "        print(\"   This is optional - you can continue with COMPAS and Adult datasets.\")\n",
        "        hmda_completed = False\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ö†Ô∏è  Error processing HMDA: {e}\")\n",
        "        print(\"   Continuing with COMPAS and Adult results.\")\n",
        "        hmda_completed = False\n",
        "\n",
        "\n",
        "    # SUMMARY\n",
        "\n",
        "\n",
        "    print(\"\\n\\n\" + \"=\"*70)\n",
        "    print(\"WEEK 1 COMPLETE - SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    datasets_completed = 2 + (1 if hmda_completed else 0)\n",
        "\n",
        "    print(f\"\\n‚úÖ Completed Tasks:\")\n",
        "    print(f\"   1. Loaded {datasets_completed} datasets successfully\")\n",
        "    print(f\"   2. Performed exploratory data analysis\")\n",
        "    print(f\"   3. Preprocessed and cleaned data\")\n",
        "    print(f\"   4. Trained 3 baseline models per dataset\")\n",
        "    print(f\"   5. Evaluated model performance\")\n",
        "    print(f\"   6. Conducted initial bias assessment\")\n",
        "\n",
        "    print(\"\\nüìä Datasets Analyzed:\")\n",
        "    print(\"   ‚úÖ COMPAS (Criminal Justice)\")\n",
        "    print(\"   ‚úÖ UCI Adult (Benefits/Economic)\")\n",
        "    if hmda_completed:\n",
        "        print(\"   ‚úÖ HMDA (Lending/Mortgage)\")\n",
        "    else:\n",
        "        print(\"   ‚ö†Ô∏è  HMDA (Skipped - optional)\")\n",
        "\n",
        "    print(\"\\nüìä Outputs Generated:\")\n",
        "    print(\"   - EDA visualizations\")\n",
        "    print(\"   - Model performance comparisons\")\n",
        "    print(\"   - Initial bias reports\")\n",
        "    print(\"   - Check the 'outputs/' folder for all visualizations\")\n",
        "\n",
        "    print(\"\\nüìù Next Steps (Week 2):\")\n",
        "    print(\"   1. Install AIF360 fairness library\")\n",
        "    print(\"   2. Calculate comprehensive fairness metrics\")\n",
        "    print(\"   3. Document baseline bias measurements\")\n",
        "    print(\"   4. Prepare for mitigation techniques\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Save your work and review the outputs folder!\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "\n",
        "\n",
        "# SAVing RESULTS FOR WEEK 2\n",
        "\n",
        "\n",
        "print(\"\\nüíæ Saving results for Week 2...\")\n",
        "\n",
        "# Save cleaned datasets\n",
        "compas_clean.to_csv('/content/drive/MyDrive/Bias/outputs/compas_clean.csv', index=False)\n",
        "adult_clean.to_csv('/content/drive/MyDrive/Bias/outputs/adult_clean.csv', index=False)\n",
        "\n",
        "# Save predictions\n",
        "pd.DataFrame({\n",
        "    'prediction': compas_results['XGBoost']['predictions'],\n",
        "    'test_index': X_test_c.index\n",
        "}).to_csv('/content/drive/MyDrive/Bias/outputs/compas_predictions.csv', index=False)\n",
        "\n",
        "pd.DataFrame({\n",
        "    'prediction': adult_results['XGBoost']['predictions'],\n",
        "    'test_index': X_test_a.index\n",
        "}).to_csv('/content/drive/MyDrive/Bias/outputs/adult_predictions.csv', index=False)\n",
        "\n",
        "# If you have HMDA\n",
        "if hmda_completed:\n",
        "    hmda_clean.to_csv('/content/drive/MyDrive/Bias/outputs/hmda_clean.csv', index=False)\n",
        "    pd.DataFrame({\n",
        "        'prediction': hmda_results['XGBoost']['predictions'],\n",
        "        'test_index': X_test_h.index\n",
        "    }).to_csv('/content/drive/MyDrive/Bias/outputs/hmda_predictions.csv', index=False)\n",
        "\n",
        "print(\"‚úÖ All results saved to outputs/ folder\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "269iM6AMomQ2",
        "outputId": "7e1da611-e57b-4a82-ce91-70a9c6a3149e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'adult_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3971534256.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m def load_adult_data(train_path=adult_data,\n\u001b[0m\u001b[1;32m     23\u001b[0m                     test_path=adult_test):\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m\"\"\"Load and prepare UCI Adult dataset\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'adult_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = xgb.XGBClassifier(n_estimators=100,use_label_encoder=False, random_state=42, eval_metric='logloss')\n",
        "\n",
        "my_adult_df = pd.read_csv(\"/content/drive/MyDrive/Bias/processed_data/adult.csv\")\n",
        "my_adult_df.head()\n",
        "adult_features = ['age', 'education-num', 'hours-per-week',\n",
        "                     'capital-gain', 'capital-loss',\n",
        "                     'workclass_encoded', 'marital-status_encoded',\n",
        "                     'occupation_encoded', 'relationship_encoded']\n",
        "X = my_adult_df[adult_features]\n",
        "y = my_adult_df['income']\n",
        "\n",
        "# Clean the 'income' column by removing periods and stripping whitespace\n",
        "y = y.astype(str).str.replace('.', '', regex=False).str.strip()\n",
        "\n",
        "\n",
        "\n",
        "# Now the mapping\n",
        "y = y.map({'<=50K': 0, '>50K': 1, \"0\": 0, \"1\": 1})\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAV6mJ6w1Hud",
        "outputId": "1848809c-318a-4537-c14f-aeecc7f78c67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in 'y' after cleaning but before mapping: <class 'str'>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.94      0.91      7170\n",
            "           1       0.79      0.64      0.70      2355\n",
            "\n",
            "    accuracy                           0.87      9525\n",
            "   macro avg       0.84      0.79      0.81      9525\n",
            "weighted avg       0.86      0.87      0.86      9525\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/MyDrive/Bias/outputs\"\n",
        "compas_clean = \"\"\n",
        "compas_prediction = \"\"\n",
        "adult_clean = \"\"\n",
        "adult_prediction = \"\"\n",
        "for root, file, filesname in os.walk(path):\n",
        "  for f in filesname:\n",
        "    if \"adult_clean\" in f:\n",
        "      adult_clean = os.path.join(root, f)\n",
        "    if \"adult_prediction\" in f:\n",
        "      adult_prediction = os.path.join(root, f)\n",
        "    if \"compas_clean\" in f:\n",
        "      compas_clean = os.path.join(root, f)\n",
        "    if \"compas_prediction\" in f:\n",
        "      compas_prediction = os.path.join(root, f)\n",
        "try:\n",
        "  print(adult_clean)\n",
        "  print(adult_prediction)\n",
        "  print(compas_clean)\n",
        "  print(compas_prediction)\n",
        "except NameError:\n",
        "  print(\"error\")"
      ],
      "metadata": {
        "id": "W6Qke9dF3N3g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b7973d8-fee1-435c-cf7d-95c0590fcb64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Bias/outputs/adult_clean.csv\n",
            "/content/drive/MyDrive/Bias/outputs/adult_predictions.csv\n",
            "/content/drive/MyDrive/Bias/outputs/compas_clean.csv\n",
            "/content/drive/MyDrive/Bias/outputs/compas_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6DeDG_Tcidv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2nd\n",
        "\n",
        "!pip install aif360\n",
        "!pip install fairlearn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "try:\n",
        "    from aif360.datasets import BinaryLabelDataset\n",
        "    from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
        "    from aif360.explainers import MetricTextExplainer\n",
        "    print(\"‚úÖ AIF360 imported successfully!\")\n",
        "except ImportError:\n",
        "    print(\"‚ùå AIF360 not found. Install with: pip install aif360\")\n",
        "    exit()\n",
        "\n",
        "# Import Fairlearn for additional metrics\n",
        "try:\n",
        "    from fairlearn.metrics import (\n",
        "        demographic_parity_difference,\n",
        "        demographic_parity_ratio,\n",
        "        equalized_odds_difference\n",
        "    )\n",
        "    print(\"‚úÖ Fairlearn imported successfully!\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è  Fairlearn not found. Install with: pip install fairlearn\")\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "\n",
        "\n",
        "# SECTION 2: HELPER FUNCTIONS FOR AIF360\n",
        "\n",
        "\n",
        "def create_aif360_dataset(df, label_name, favorable_label,\n",
        "                          protected_attribute_names,\n",
        "                          privileged_protected_attributes):\n",
        "    \"\"\"\n",
        "    Convert pandas DataFrame to AIF360 BinaryLabelDataset\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pandas DataFrame\n",
        "    label_name : str - name of target column\n",
        "    favorable_label : int - positive class (1 for approved, 0 for denied)\n",
        "    protected_attribute_names : list - ['race', 'sex']\n",
        "    privileged_protected_attributes : list of dicts - [{'race': 1}, {'sex': 1}]\n",
        "    \"\"\"\n",
        "\n",
        "    return BinaryLabelDataset(\n",
        "        favorable_label=favorable_label,\n",
        "        unfavorable_label=1 - favorable_label,\n",
        "        df=df,\n",
        "        label_names=[label_name],\n",
        "        protected_attribute_names=protected_attribute_names,\n",
        "        privileged_protected_attributes=privileged_protected_attributes\n",
        "    )\n",
        "\n",
        "def calculate_all_fairness_metrics(dataset_true, dataset_pred,\n",
        "                                   unprivileged_groups, privileged_groups,\n",
        "                                   dataset_name=\"Dataset\"):\n",
        "    \"\"\"\n",
        "    Calculate comprehensive fairness metrics using AIF360\n",
        "\n",
        "    Returns: Dictionary with all metrics\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"FAIRNESS METRICS ANALYSIS: {dataset_name}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Create metrics object\n",
        "    metric = ClassificationMetric(\n",
        "        dataset_true,\n",
        "        dataset_pred,\n",
        "        unprivileged_groups=unprivileged_groups,\n",
        "        privileged_groups=privileged_groups\n",
        "    )\n",
        "\n",
        "    metrics_dict = {}\n",
        "\n",
        "\n",
        "    # GROUP FAIRNESS METRICS\n",
        "\n",
        "\n",
        "    print(\"\\nüìä GROUP FAIRNESS METRICS\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    # 1. Statistical Parity Difference (Demographic Parity)\n",
        "    spd = metric.statistical_parity_difference()\n",
        "    metrics_dict['statistical_parity_difference'] = spd\n",
        "    print(f\"\\n1. Statistical Parity Difference: {spd:.4f}\")\n",
        "    print(f\"   Interpretation: Difference in positive prediction rates\")\n",
        "    print(f\"   Ideal value: 0 (no difference)\")\n",
        "    print(f\"   Threshold: |SPD| < 0.10 is acceptable\")\n",
        "    if abs(spd) > 0.10:\n",
        "        print(f\"   ‚ö†Ô∏è  WARNING: Exceeds fairness threshold!\")\n",
        "    else:\n",
        "        print(f\"   ‚úÖ Within acceptable range\")\n",
        "\n",
        "    # 2. Disparate Impact\n",
        "    di = metric.disparate_impact()\n",
        "    metrics_dict['disparate_impact'] = di\n",
        "    print(f\"\\n2. Disparate Impact Ratio: {di:.4f}\")\n",
        "    print(f\"   Interpretation: Ratio of positive rates (unprivileged/privileged)\")\n",
        "    print(f\"   Ideal value: 1.0 (equal rates)\")\n",
        "    print(f\"   Legal threshold: DI ‚â• 0.80 (EEOC 80% rule)\")\n",
        "    if di < 0.80:\n",
        "        print(f\"   ‚ö†Ô∏è  LEGAL VIOLATION: Below 0.80 threshold!\")\n",
        "    elif di > 1.25:\n",
        "        print(f\"   ‚ö†Ô∏è  WARNING: Reverse discrimination (DI > 1.25)\")\n",
        "    else:\n",
        "        print(f\"   ‚úÖ Within legal bounds\")\n",
        "\n",
        "    # 3. Equal Opportunity Difference (TPR difference)\n",
        "    eod = metric.equal_opportunity_difference()\n",
        "    metrics_dict['equal_opportunity_difference'] = eod\n",
        "    print(f\"\\n3. Equal Opportunity Difference: {eod:.4f}\")\n",
        "    print(f\"   Interpretation: Difference in True Positive Rates\")\n",
        "    print(f\"   Ideal value: 0 (equal TPR across groups)\")\n",
        "    print(f\"   Measures: Are qualified people from both groups accepted equally?\")\n",
        "    if abs(eod) > 0.10:\n",
        "        print(f\"   ‚ö†Ô∏è  Significant difference in opportunity\")\n",
        "    else:\n",
        "        print(f\"   ‚úÖ Similar opportunity across groups\")\n",
        "\n",
        "    # 4. Average Odds Difference (Equalized Odds)\n",
        "    aod = metric.average_odds_difference()\n",
        "    metrics_dict['average_odds_difference'] = aod\n",
        "    print(f\"\\n4. Average Odds Difference: {aod:.4f}\")\n",
        "    print(f\"   Interpretation: Average of TPR and FPR differences\")\n",
        "    print(f\"   Ideal value: 0 (equal error rates)\")\n",
        "    print(f\"   Measures: Overall fairness in predictions\")\n",
        "    if abs(aod) > 0.10:\n",
        "        print(f\"   ‚ö†Ô∏è  Significant difference in error rates\")\n",
        "    else:\n",
        "        print(f\"   ‚úÖ Similar error rates across groups\")\n",
        "\n",
        "    # 5. Theil Index (measures inequality)\n",
        "    theil = metric.theil_index()\n",
        "    metrics_dict['theil_index'] = theil\n",
        "    print(f\"\\n5. Theil Index: {theil:.4f}\")\n",
        "    print(f\"   Interpretation: Measures inequality in benefit allocation\")\n",
        "    print(f\"   Ideal value: 0 (perfect equality)\")\n",
        "    print(f\"   Range: [0, ‚àû)\")\n",
        "\n",
        "\n",
        "    # INDIVIDUAL FAIRNESS METRICS\n",
        "\n",
        "\n",
        "    print(\"\\n\\nüìä INDIVIDUAL FAIRNESS METRICS\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    # 6. Consistency Score\n",
        "    # Note: Requires individual fairness calculation (computationally expensive)\n",
        "    # We'll calculate a proxy using prediction variance within similar groups\n",
        "\n",
        "    print(\"\\n6. Consistency Analysis\")\n",
        "    print(\"   (Simplified proxy - full individual fairness requires k-NN)\")\n",
        "    print(\"   Measures: Similar individuals get similar predictions\")\n",
        "\n",
        "\n",
        "    # PERFORMANCE METRICS BY GROUP\n",
        "\n",
        "\n",
        "    print(\"\\n\\nüìä PERFORMANCE METRICS BY GROUP\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    # True Positive Rates\n",
        "    tpr_priv = metric.true_positive_rate(privileged=True)\n",
        "    tpr_unpriv = metric.true_positive_rate(privileged=False)\n",
        "    metrics_dict['tpr_privileged'] = tpr_priv\n",
        "    metrics_dict['tpr_unprivileged'] = tpr_unpriv\n",
        "\n",
        "    print(f\"\\n7. True Positive Rate (Sensitivity/Recall)\")\n",
        "    print(f\"   Privileged group: {tpr_priv:.4f}\")\n",
        "    print(f\"   Unprivileged group: {tpr_unpriv:.4f}\")\n",
        "    print(f\"   Difference: {abs(tpr_priv - tpr_unpriv):.4f}\")\n",
        "\n",
        "    # False Positive Rates\n",
        "    fpr_priv = metric.false_positive_rate(privileged=True)\n",
        "    fpr_unpriv = metric.false_positive_rate(privileged=False)\n",
        "    metrics_dict['fpr_privileged'] = fpr_priv\n",
        "    metrics_dict['fpr_unprivileged'] = fpr_unpriv\n",
        "\n",
        "    print(f\"\\n8. False Positive Rate\")\n",
        "    print(f\"   Privileged group: {fpr_priv:.4f}\")\n",
        "    print(f\"   Unprivileged group: {fpr_unpriv:.4f}\")\n",
        "    print(f\"   Difference: {abs(fpr_priv - fpr_unpriv):.4f}\")\n",
        "\n",
        "    # Positive Prediction Rates\n",
        "    ppr_priv = metric.positive_rate(privileged=True)\n",
        "    ppr_unpriv = metric.positive_rate(privileged=False)\n",
        "    metrics_dict['positive_rate_privileged'] = ppr_priv\n",
        "    metrics_dict['positive_rate_unprivileged'] = ppr_unpriv\n",
        "\n",
        "    print(f\"\\n9. Positive Prediction Rate\")\n",
        "    print(f\"   Privileged group: {ppr_priv:.4f}\")\n",
        "    print(f\"   Unprivileged group: {ppr_unpriv:.4f}\")\n",
        "    print(f\"   Difference: {abs(ppr_priv - ppr_unpriv):.4f}\")\n",
        "\n",
        "    # Selection Rates\n",
        "    print(f\"\\n10. Selection Rate Analysis\")\n",
        "    print(f\"    % Selected (Privileged): {ppr_priv*100:.2f}%\")\n",
        "    print(f\"    % Selected (Unprivileged): {ppr_unpriv*100:.2f}%\")\n",
        "    print(f\"    Ratio: {ppr_unpriv/ppr_priv if ppr_priv > 0 else 0:.4f}\")\n",
        "\n",
        "    # Accuracy by group\n",
        "    acc_priv = metric.accuracy(privileged=True)\n",
        "    acc_unpriv = metric.accuracy(privileged=False)\n",
        "    metrics_dict['accuracy_privileged'] = acc_priv\n",
        "    metrics_dict['accuracy_unprivileged'] = acc_unpriv\n",
        "\n",
        "    print(f\"\\n11. Accuracy by Group\")\n",
        "    print(f\"    Privileged group: {acc_priv:.4f}\")\n",
        "    print(f\"    Unprivileged group: {acc_unpriv:.4f}\")\n",
        "    print(f\"    Difference: {abs(acc_priv - acc_unpriv):.4f}\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # BIAS SEVERITY ASSESSMENT\n",
        "    # ========================================================================\n",
        "\n",
        "    print(\"\\n\\n\" + \"=\"*70)\n",
        "    print(\"BIAS SEVERITY ASSESSMENT\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    severity_score = 0\n",
        "    issues = []\n",
        "\n",
        "    if abs(spd) > 0.10:\n",
        "        severity_score += 2\n",
        "        issues.append(\"Statistical parity violated\")\n",
        "\n",
        "    if di < 0.80 or di > 1.25:\n",
        "        severity_score += 3  # Legal threshold\n",
        "        issues.append(\"Disparate impact violation (LEGAL ISSUE)\")\n",
        "\n",
        "    if abs(eod) > 0.10:\n",
        "        severity_score += 2\n",
        "        issues.append(\"Unequal opportunity detected\")\n",
        "\n",
        "    if abs(aod) > 0.10:\n",
        "        severity_score += 2\n",
        "        issues.append(\"Unequal error rates\")\n",
        "\n",
        "    if abs(tpr_priv - tpr_unpriv) > 0.15:\n",
        "        severity_score += 1\n",
        "        issues.append(\"Large TPR difference\")\n",
        "\n",
        "    if abs(fpr_priv - fpr_unpriv) > 0.15:\n",
        "        severity_score += 1\n",
        "        issues.append(\"Large FPR difference\")\n",
        "\n",
        "    print(f\"\\nBias Severity Score: {severity_score}/11\")\n",
        "    print(f\"Severity Level: \", end=\"\")\n",
        "\n",
        "    if severity_score == 0:\n",
        "        print(\"‚úÖ MINIMAL - No significant bias detected\")\n",
        "    elif severity_score <= 3:\n",
        "        print(\"‚ö†Ô∏è  LOW - Minor fairness concerns\")\n",
        "    elif severity_score <= 6:\n",
        "        print(\"‚ö†Ô∏è  MODERATE - Significant bias, mitigation recommended\")\n",
        "    elif severity_score <= 9:\n",
        "        print(\"üö® HIGH - Serious bias, mitigation required\")\n",
        "    else:\n",
        "        print(\"üö® CRITICAL - Severe bias, immediate action required\")\n",
        "\n",
        "    if issues:\n",
        "        print(f\"\\nIssues detected:\")\n",
        "        for i, issue in enumerate(issues, 1):\n",
        "            print(f\"  {i}. {issue}\")\n",
        "\n",
        "    return metrics_dict\n",
        "\n",
        "# ============================================================================\n",
        "# SECTION 3: VISUALIZATION FUNCTIONS\n",
        "\n",
        "\n",
        "def visualize_fairness_metrics(metrics_dict, dataset_name):\n",
        "    \"\"\"Create comprehensive fairness visualization\"\"\"\n",
        "\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "    fig.suptitle(f'{dataset_name} - Comprehensive Fairness Analysis',\n",
        "                 fontsize=16, fontweight='bold')\n",
        "\n",
        "    # 1. Disparate Impact\n",
        "    ax = axes[0, 0]\n",
        "    di = metrics_dict['disparate_impact']\n",
        "    colors = ['red' if di < 0.8 else 'yellow' if di < 0.9 else 'green']\n",
        "    ax.bar(['Disparate\\nImpact'], [di], color=colors[0], alpha=0.7)\n",
        "    ax.axhline(y=0.8, color='red', linestyle='--', label='Legal threshold')\n",
        "    ax.axhline(y=1.0, color='green', linestyle='--', label='Perfect fairness')\n",
        "    ax.set_ylabel('Ratio')\n",
        "    ax.set_title('Disparate Impact\\n(Legal Threshold: 0.80)')\n",
        "    ax.legend()\n",
        "    ax.set_ylim([0, max(1.5, di + 0.2)])\n",
        "\n",
        "    # 2. Statistical Parity\n",
        "    ax = axes[0, 1]\n",
        "    spd = metrics_dict['statistical_parity_difference']\n",
        "    color = 'red' if abs(spd) > 0.1 else 'green'\n",
        "    ax.bar(['Statistical Parity\\nDifference'], [spd], color=color, alpha=0.7)\n",
        "    ax.axhline(y=0, color='green', linestyle='--', label='Perfect parity')\n",
        "    ax.axhline(y=0.1, color='orange', linestyle='--', label='Threshold')\n",
        "    ax.axhline(y=-0.1, color='orange', linestyle='--')\n",
        "    ax.set_ylabel('Difference')\n",
        "    ax.set_title('Statistical Parity Difference\\n(Threshold: \\u00b10.10)')\n",
        "    ax.legend()\n",
        "\n",
        "    # 3. True Positive Rates\n",
        "    ax = axes[0, 2]\n",
        "    tpr_data = [metrics_dict['tpr_privileged'],\n",
        "                metrics_dict['tpr_unprivileged']]\n",
        "    bars = ax.bar(['Privileged', 'Unprivileged'], tpr_data,\n",
        "                   color=['steelblue', 'coral'], alpha=0.7)\n",
        "    ax.set_ylabel('Rate')\n",
        "    ax.set_title('True Positive Rate by Group')\n",
        "    ax.set_ylim([0, 1])\n",
        "    # Add value labels\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:.3f}', ha='center', va='bottom')\n",
        "\n",
        "    # 4. False Positive Rates\n",
        "    ax = axes[1, 0]\n",
        "    fpr_data = [metrics_dict['fpr_privileged'],\n",
        "                metrics_dict['fpr_unprivileged']]\n",
        "    bars = ax.bar(['Privileged', 'Unprivileged'], fpr_data,\n",
        "                   color=['steelblue', 'coral'], alpha=0.7)\n",
        "    ax.set_ylabel('Rate')\n",
        "    ax.set_title('False Positive Rate by Group')\n",
        "    ax.set_ylim([0, 1])\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:.3f}', ha='center', va='bottom')\n",
        "\n",
        "    # 5. Selection Rates\n",
        "    ax = axes[1, 1]\n",
        "    sel_data = [metrics_dict['positive_rate_privileged'],\n",
        "                metrics_dict['positive_rate_unprivileged']]\n",
        "    bars = ax.bar(['Privileged', 'Unprivileged'], sel_data,\n",
        "                   color=['steelblue', 'coral'], alpha=0.7)\n",
        "    ax.set_ylabel('Rate')\n",
        "    ax.set_title('Positive Prediction Rate\\n(Selection Rate)')\n",
        "    ax.set_ylim([0, 1])\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:.3f}', ha='center', va='bottom')\n",
        "\n",
        "    # 6. Accuracy by Group\n",
        "    ax = axes[1, 2]\n",
        "    acc_data = [metrics_dict['accuracy_privileged'],\n",
        "                metrics_dict['accuracy_unprivileged']]\n",
        "    bars = ax.bar(['Privileged', 'Unprivileged'], acc_data,\n",
        "                   color=['steelblue', 'coral'], alpha=0.7)\n",
        "    ax.set_ylabel('Accuracy')\n",
        "    ax.set_title('Model Accuracy by Group')\n",
        "    ax.set_ylim([0, 1])\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:.3f}', ha='center', va='bottom')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'outputs/{dataset_name}_fairness_metrics.png',\n",
        "                dpi=300, bbox_inches='tight')\n",
        "    print(f\"\\nüìä Visualization saved: outputs/{dataset_name}_fairness_metrics.png\")\n",
        "    plt.show()\n",
        "\n",
        "def create_fairness_report(all_metrics, dataset_names):\n",
        "    \"\"\"Create summary table of all fairness metrics\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"FAIRNESS METRICS COMPARISON ACROSS DATASETS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    metrics_to_compare = [\n",
        "        'disparate_impact',\n",
        "        'statistical_parity_difference',\n",
        "        'equal_opportunity_difference',\n",
        "        'average_odds_difference',\n",
        "        'tpr_unprivileged',\n",
        "        'fpr_unprivileged'\n",
        "    ]\n",
        "\n",
        "    comparison_data = []\n",
        "    for dataset_name in dataset_names:\n",
        "        row = {'Dataset': dataset_name}\n",
        "        for metric in metrics_to_compare:\n",
        "            if metric in all_metrics[dataset_name]:\n",
        "                row[metric] = all_metrics[dataset_name][metric]\n",
        "        comparison_data.append(row)\n",
        "\n",
        "    df_comparison = pd.DataFrame(comparison_data)\n",
        "\n",
        "    # Rename columns for readability\n",
        "    df_comparison.columns = [\n",
        "        'Dataset', 'Disparate Impact', 'Stat. Parity Diff',\n",
        "        'Equal Opp. Diff', 'Avg Odds Diff',\n",
        "        'TPR (Unpriv)', 'FPR (Unpriv)'\n",
        "    ]\n",
        "\n",
        "    print(\"\\n\" + df_comparison.to_string(index=False))\n",
        "\n",
        "    # Save to CSV\n",
        "    df_comparison.to_csv('outputs/fairness_metrics_comparison.csv', index=False)\n",
        "    print(\"\\nüíæ Saved: outputs/fairness_metrics_comparison.csv\")\n",
        "\n",
        "    return df_comparison\n",
        "\n",
        "\n",
        "# SECTION 4: MAIN ANALYSIS PIPELINE\n",
        "\n",
        "\n",
        "def analyze_compas_fairness(df, predictions, model_name=\"XGBoost\"):\n",
        "    \"\"\"Comprehensive fairness analysis for COMPAS dataset\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"#\"*70)\n",
        "    print(\"# COMPAS FAIRNESS ANALYSIS\")\n",
        "    print(\"#\"*70)\n",
        "\n",
        "    # Prepare data\n",
        "    df_analysis = df.copy()\n",
        "    df_analysis['prediction'] = predictions\n",
        "\n",
        "    # The dataframe for AIF360 should only contain the actual features,\n",
        "    # the protected attributes, and *one* of the label columns (target or prediction).\n",
        "    # This ensures that 'target' isn't treated as a feature when 'prediction' is the label, and vice versa.\n",
        "\n",
        "    # Determine common features (excluding 'target' and 'prediction')\n",
        "    common_features = [col for col in df_analysis.columns if col not in ['target', 'prediction']]\n",
        "    protected_attribute_names_compas = ['race_binary'] # From the original code context for COMPAS\n",
        "\n",
        "    # DataFrame for true labels (dataset_true)\n",
        "    # It should include common features, protected attributes, and the 'target' column\n",
        "    df_true_for_aif = df_analysis[common_features + protected_attribute_names_compas + ['target']]\n",
        "\n",
        "    # DataFrame for predicted labels (dataset_pred)\n",
        "    # It should include common features, protected attributes, and the 'prediction' column\n",
        "    df_pred_for_aif = df_analysis[common_features + protected_attribute_names_compas + ['prediction']]\n",
        "\n",
        "    # Create AIF360 datasets\n",
        "    dataset_true = create_aif360_dataset(\n",
        "        df_true_for_aif,\n",
        "        label_name='target',\n",
        "        favorable_label=0,  # 0 = no recidivism (good outcome)\n",
        "        protected_attribute_names=protected_attribute_names_compas,\n",
        "        privileged_protected_attributes=[{'race_binary': 1}]  # 1 = White\n",
        "    )\n",
        "\n",
        "    dataset_pred = create_aif360_dataset(\n",
        "        df_pred_for_aif,\n",
        "        label_name='prediction',\n",
        "        favorable_label=0,\n",
        "        protected_attribute_names=protected_attribute_names_compas,\n",
        "        privileged_protected_attributes=[{'race_binary': 1}]\n",
        "    )\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = calculate_all_fairness_metrics(\n",
        "        dataset_true,\n",
        "        dataset_pred,\n",
        "        unprivileged_groups=[{'race_binary': 0}],  # Non-white\n",
        "        privileged_groups=[{'race_binary': 1}],    # White\n",
        "        dataset_name=f\"COMPAS ({model_name})\"\n",
        "    )\n",
        "\n",
        "    # Visualize\n",
        "    visualize_fairness_metrics(metrics, f\"COMPAS_{model_name}\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def analyze_adult_fairness(df, predictions, model_name=\"XGBoost\"):\n",
        "    \"\"\"Comprehensive fairness analysis for UCI Adult dataset\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"#\"*70)\n",
        "    print(\"# UCI ADULT FAIRNESS ANALYSIS\")\n",
        "    print(\"#\"*70)\n",
        "\n",
        "    # Prepare data\n",
        "    df_analysis = df.copy()\n",
        "    df_analysis['prediction'] = predictions\n",
        "\n",
        "    # Determine common features (excluding 'target' and 'prediction')\n",
        "    common_features = [col for col in df_analysis.columns if col not in ['target', 'prediction']]\n",
        "    protected_attribute_names_adult = ['race_binary'] # Using race_binary as in initial bias check\n",
        "\n",
        "    # DataFrame for true labels (dataset_true)\n",
        "    df_true_for_aif = df_analysis[common_features + protected_attribute_names_adult + ['target']]\n",
        "\n",
        "    # DataFrame for predicted labels (dataset_pred)\n",
        "    df_pred_for_aif = df_analysis[common_features + protected_attribute_names_adult + ['prediction']]\n",
        "\n",
        "    # Create AIF360 datasets\n",
        "    dataset_true = create_aif360_dataset(\n",
        "        df_true_for_aif,\n",
        "        label_name='target',\n",
        "        favorable_label=1,  # 1 = high income (good outcome)\n",
        "        protected_attribute_names=protected_attribute_names_adult,\n",
        "        privileged_protected_attributes=[{'race_binary': 1}]  # 1 = White\n",
        "    )\n",
        "\n",
        "    dataset_pred = create_aif360_dataset(\n",
        "        df_pred_for_aif,\n",
        "        label_name='prediction',\n",
        "        favorable_label=1,\n",
        "        protected_attribute_names=protected_attribute_names_adult,\n",
        "        privileged_protected_attributes=[{'race_binary': 1}]\n",
        "    )\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = calculate_all_fairness_metrics(\n",
        "        dataset_true,\n",
        "        dataset_pred,\n",
        "        unprivileged_groups=[{'race_binary': 0}],  # Non-white\n",
        "        privileged_groups=[{'race_binary': 1}],    # White\n",
        "        dataset_name=f\"UCI_Adult ({model_name})\"\n",
        "    )\n",
        "\n",
        "    # Visualize\n",
        "    visualize_fairness_metrics(metrics, f\"UCI_Adult_{model_name}\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# MAIN EXECUTION\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"FEDERAL AI BIAS RESEARCH - WEEK 2\")\n",
        "    print(\"Comprehensive Bias Detection & Fairness Metrics\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\\n‚ö†Ô∏è  NOTE: This script requires Week 1 data.\")\n",
        "    print(\"Make sure you have:\")\n",
        "    print(\"  1. Trained models from Week 1\")\n",
        "    print(\"  2. Test predictions saved\")\n",
        "    print(\"  3. Preprocessed datasets\")\n",
        "\n",
        "\n",
        "    # LOAD WEEK 1 RESULTS\n",
        "\n",
        "\n",
        "    print(\"\\nüìÇ Loading Week 1 results...\")\n",
        "\n",
        "    # You'll need to save these from Week 1 or re-run Week 1 preprocessing\n",
        "    # For now, this is a template showing what you need\n",
        "\n",
        "    \"\"\"\n",
        "    Example of what you need from Week 1:\n",
        "\n",
        "    - compas_clean: preprocessed COMPAS dataframe\n",
        "    - compas_predictions: XGBoost predictions on test set\n",
        "    - compas_test_indices: indices of test samples\n",
        "\n",
        "    - adult_clean: preprocessed Adult dataframe\n",
        "    - adult_predictions: XGBoost predictions on test set\n",
        "    - adult_test_indices: indices of test samples\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"INSTRUCTIONS FOR RUNNING WEEK 2\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\"\"\n",
        "    To run this analysis, you need to:\n",
        "\n",
        "    1. Run Week 1 code first and save these variables:\n",
        "       - Preprocessed dataframes\n",
        "       - Model predictions\n",
        "       - Test set indices\n",
        "\n",
        "    2. Then load them here and run fairness analysis\n",
        "\n",
        "    Example code to add at end of Week 1:\n",
        "\n",
        "    # Save for Week 2\n",
        "    compas_clean.to_csv('outputs/compas_clean.csv', index=False)\n",
        "    adult_clean.to_csv('outputs/adult_clean.csv', index=False)\n",
        "\n",
        "    pd.DataFrame({\n",
        "        'prediction': compas_results['XGBoost']['predictions']\n",
        "    }).to_csv('outputs/compas_predictions.csv', index=False)\n",
        "\n",
        "    pd.DataFrame({\n",
        "        'prediction': adult_results['XGBoost']['predictions']\n",
        "    }).to_csv('outputs/adult_predictions.csv', index=False)\n",
        "\n",
        "    pd.DataFrame({\n",
        "        'test_index': X_test_c.index\n",
        "    }).to_csv('outputs/compas_test_indices.csv', index=False)\n",
        "\n",
        "    pd.DataFrame({\n",
        "        'test_index': X_test_a.index\n",
        "    }).to_csv('outputs/adult_test_indices.csv', index=False)\n",
        "    \"\"\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"DEMO: Running on Sample Data\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Create sample data for demonstration\n",
        "    print(\"\\nCreating sample data for demonstration...\")\n",
        "\n",
        "    np.random.seed(42)\n",
        "    n_samples = 1000\n",
        "\n",
        "    # Sample COMPAS-like data\n",
        "    sample_compas = pd.DataFrame({\n",
        "        'age': np.random.randint(18, 65, n_samples),\n",
        "        'priors_count': np.random.poisson(2, n_samples),\n",
        "        'race_binary': np.random.binomial(1, 0.7, n_samples),  # 70% privileged\n",
        "        'sex_binary': np.random.binomial(1, 0.6, n_samples),\n",
        "        'target': np.random.binomial(1, 0.45, n_samples)\n",
        "    })\n",
        "\n",
        "    # Create biased predictions (intentionally worse for unprivileged)\n",
        "    sample_compas['prediction'] = sample_compas['target'].copy()\n",
        "    # Add bias: increase false positives for unprivileged group\n",
        "    bias_mask = (sample_compas['race_binary'] == 0) & (sample_compas['target'] == 0)\n",
        "    sample_compas.loc[bias_mask, 'prediction'] = np.random.binomial(\n",
        "        1, 0.3, bias_mask.sum()) # Use sum of bias_mask for size parameter\n",
        "\n",
        "    print(f\"‚úÖ Created sample COMPAS data: {len(sample_compas)} records\")\n",
        "\n",
        "    # Analyze sample data\n",
        "    sample_metrics = analyze_compas_fairness(\n",
        "        sample_compas,\n",
        "        sample_compas['prediction'].values,\n",
        "        model_name=\"Sample_Demo\"\n",
        "    )\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"WEEK 2 SETUP COMPLETE\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\"\"\n",
        "    ‚úÖ AIF360 working correctly!\n",
        "    ‚úÖ Fairness metrics calculated successfully\n",
        "    ‚úÖ Visualizations generated\n",
        "\n",
        "    üìù Next steps:\n",
        "    1. Add save commands to Week 1 code (see instructions above)\n",
        "    2. Re-run Week 1 to generate saved files\n",
        "    3. Update this script to load your actual data\n",
        "    4. Run full fairness analysis on all datasets\n",
        "\n",
        "    Then move to Week 3: Bias Mitigation!\n",
        "    \"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MrBFEofiFOX5",
        "outputId": "70d6ae95-5547-425c-de4c-5c06f0587bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aif360 in /usr/local/lib/python3.12/dist-packages (0.6.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.12/dist-packages (from aif360) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from aif360) (1.15.3)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from aif360) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.12/dist-packages (from aif360) (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from aif360) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.0->aif360) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.0->aif360) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.0->aif360) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0->aif360) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0->aif360) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->aif360) (1.17.0)\n",
            "Requirement already satisfied: fairlearn in /usr/local/lib/python3.12/dist-packages (0.13.0)\n",
            "Requirement already satisfied: narwhals>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from fairlearn) (2.11.0)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.12/dist-packages (from fairlearn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from fairlearn) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from fairlearn) (1.6.1)\n",
            "Requirement already satisfied: scipy<1.16.0,>=1.9.3 in /usr/local/lib/python3.12/dist-packages (from fairlearn) (1.15.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.3->fairlearn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2.1->fairlearn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2.1->fairlearn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.17.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
            "pip install 'aif360[inFairness]'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ AIF360 imported successfully!\n",
            "‚úÖ Fairlearn imported successfully!\n",
            "\n",
            "======================================================================\n",
            "FEDERAL AI BIAS RESEARCH - WEEK 2\n",
            "Comprehensive Bias Detection & Fairness Metrics\n",
            "======================================================================\n",
            "\n",
            "‚ö†Ô∏è  NOTE: This script requires Week 1 data.\n",
            "Make sure you have:\n",
            "  1. Trained models from Week 1\n",
            "  2. Test predictions saved\n",
            "  3. Preprocessed datasets\n",
            "\n",
            "üìÇ Loading Week 1 results...\n",
            "\n",
            "======================================================================\n",
            "INSTRUCTIONS FOR RUNNING WEEK 2\n",
            "======================================================================\n",
            "\n",
            "    To run this analysis, you need to:\n",
            "    \n",
            "    1. Run Week 1 code first and save these variables:\n",
            "       - Preprocessed dataframes\n",
            "       - Model predictions\n",
            "       - Test set indices\n",
            "    \n",
            "    2. Then load them here and run fairness analysis\n",
            "    \n",
            "    Example code to add at end of Week 1:\n",
            "    \n",
            "    # Save for Week 2\n",
            "    compas_clean.to_csv('outputs/compas_clean.csv', index=False)\n",
            "    adult_clean.to_csv('outputs/adult_clean.csv', index=False)\n",
            "    \n",
            "    pd.DataFrame({\n",
            "        'prediction': compas_results['XGBoost']['predictions']\n",
            "    }).to_csv('outputs/compas_predictions.csv', index=False)\n",
            "    \n",
            "    pd.DataFrame({\n",
            "        'prediction': adult_results['XGBoost']['predictions']\n",
            "    }).to_csv('outputs/adult_predictions.csv', index=False)\n",
            "    \n",
            "    pd.DataFrame({\n",
            "        'test_index': X_test_c.index\n",
            "    }).to_csv('outputs/compas_test_indices.csv', index=False)\n",
            "    \n",
            "    pd.DataFrame({\n",
            "        'test_index': X_test_a.index\n",
            "    }).to_csv('outputs/adult_test_indices.csv', index=False)\n",
            "    \n",
            "\n",
            "======================================================================\n",
            "DEMO: Running on Sample Data\n",
            "======================================================================\n",
            "\n",
            "Creating sample data for demonstration...\n",
            "‚úÖ Created sample COMPAS data: 1000 records\n",
            "\n",
            "######################################################################\n",
            "# COMPAS FAIRNESS ANALYSIS\n",
            "######################################################################\n",
            "\n",
            "======================================================================\n",
            "FAIRNESS METRICS ANALYSIS: COMPAS (Sample_Demo)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The two datasets are expected to differ only in 'labels' or 'scores'.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-759643428.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0;31m# Analyze sample data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m     sample_metrics = analyze_compas_fairness(\n\u001b[0m\u001b[1;32m    623\u001b[0m         \u001b[0msample_compas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0msample_compas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-759643428.py\u001b[0m in \u001b[0;36manalyze_compas_fairness\u001b[0;34m(df, predictions, model_name)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;31m# Calculate metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     metrics = calculate_all_fairness_metrics(\n\u001b[0m\u001b[1;32m    459\u001b[0m         \u001b[0mdataset_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mdataset_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-759643428.py\u001b[0m in \u001b[0;36mcalculate_all_fairness_metrics\u001b[0;34m(dataset_true, dataset_pred, unprivileged_groups, privileged_groups, dataset_name)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# Create metrics object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     metric = ClassificationMetric(\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mdataset_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mdataset_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/aif360/metrics/classification_metric.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, classified_dataset, unprivileged_groups, privileged_groups)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporarily_ignore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scores'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassified_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 raise ValueError(\"The two datasets are expected to differ only \"\n\u001b[0m\u001b[1;32m     68\u001b[0m                                  \"in 'labels' or 'scores'.\")\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The two datasets are expected to differ only in 'labels' or 'scores'."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r9qClkx5Z3Se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOBJqRULEGEP",
        "outputId": "acdac150-8bbc-4d96-f558-2283d2188628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "FEDERAL AI BIAS DETECTION - MULTI-DOMAIN ANALYSIS\n",
            "Analyzing 3 domains: Criminal Justice, Lending, Healthcare\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "DATASET 1: COMPAS - CRIMINAL JUSTICE RECIDIVISM\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "DATASET 2: ADULT INCOME - LENDING/CREDIT DECISIONS\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "DATASET 3: HEALTHCARE - DIABETES HOSPITAL READMISSION\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "STARTING MULTI-DOMAIN BIAS ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "üîç Analyzing Dataset 1/3: COMPAS (Criminal Justice)...\n",
            "\n",
            "[1/6] Loading COMPAS dataset...\n",
            "‚úì Dataset loaded: 7214 records\n",
            "[2/6] Preprocessing COMPAS data...\n",
            "‚úì Filtered: 6150 records\n",
            "  - African-American: 3696\n",
            "  - Caucasian: 2454\n",
            "[3/6] Training COMPAS model...\n",
            "‚úì Model trained - Accuracy: 69.43%\n",
            "[4/6] Calculating COMPAS bias metrics...\n",
            "\n",
            "================================================================================\n",
            "BIAS DETECTION RESULTS - COMPAS - Criminal Justice\n",
            "================================================================================\n",
            "\n",
            "üìä LEGAL COMPLIANCE CHECK:\n",
            "   Disparate Impact: 1.862 (FAIL ‚úó)\n",
            "   EEOC Threshold: 0.80 - 1.25 (legal range)\n",
            "\n",
            "   ‚ö†Ô∏è  LEGAL VIOLATION DETECTED\n",
            "   Unprivileged group 1.86x more likely to get favorable outcome (reverse discrimination)\n",
            "\n",
            "üìà DETAILED METRICS:\n",
            "   Statistical Parity: 0.236\n",
            "   Equal Opportunity: 0.165\n",
            "   FPR Difference: 0.215\n",
            "   Accuracy Difference: -0.064\n",
            "\n",
            "üî¢ PREDICTION RATES:\n",
            "   Privileged group: 27.4%\n",
            "   Unprivileged group: 51.0%\n",
            "\n",
            "üë• SAMPLE SIZES:\n",
            "   Privileged: 744\n",
            "   Unprivileged: 1,101\n",
            "‚úì COMPAS analysis complete\n",
            "\n",
            "üîç Analyzing Dataset 2/3: Adult Income (Lending)...\n",
            "\n",
            "[1/6] Loading Adult Income dataset...\n",
            "‚úì Dataset loaded: 32561 records\n",
            "[2/6] Preprocessing Adult data...\n",
            "‚úì Filtered: 30940 records\n",
            "  - Black: 3124\n",
            "  - White: 27816\n",
            "[3/6] Training Adult Income model...\n",
            "‚úì Model trained - Accuracy: 82.36%\n",
            "[4/6] Calculating Adult Income bias metrics...\n",
            "\n",
            "================================================================================\n",
            "BIAS DETECTION RESULTS - Adult Income - Lending/Credit\n",
            "================================================================================\n",
            "\n",
            "üìä LEGAL COMPLIANCE CHECK:\n",
            "   Disparate Impact: 0.401 (FAIL ‚úó)\n",
            "   EEOC Threshold: 0.80 - 1.25 (legal range)\n",
            "\n",
            "   ‚ö†Ô∏è  LEGAL VIOLATION DETECTED\n",
            "   Privileged group 2.49x more likely to get favorable outcome\n",
            "\n",
            "üìà DETAILED METRICS:\n",
            "   Statistical Parity: -0.091\n",
            "   Equal Opportunity: -0.105\n",
            "   FPR Difference: -0.030\n",
            "   Accuracy Difference: 0.083\n",
            "\n",
            "üî¢ PREDICTION RATES:\n",
            "   Privileged group: 15.2%\n",
            "   Unprivileged group: 6.1%\n",
            "\n",
            "üë• SAMPLE SIZES:\n",
            "   Privileged: 8,345\n",
            "   Unprivileged: 937\n",
            "‚úì Adult Income analysis complete\n",
            "\n",
            "üîç Analyzing Dataset 3/3: Healthcare (Readmission)...\n",
            "\n",
            "[1/6] Loading Healthcare dataset...\n",
            "‚úì Dataset loaded: 101766 records\n",
            "[2/6] Preprocessing Healthcare data...\n",
            "‚úì Filtered: 95309 records\n",
            "  - African American: 19210\n",
            "  - Caucasian: 76099\n",
            "[3/6] Training Healthcare model...\n",
            "‚úì Model trained - Accuracy: 88.72%\n",
            "[4/6] Calculating Healthcare bias metrics...\n",
            "\n",
            "================================================================================\n",
            "BIAS DETECTION RESULTS - Healthcare - Hospital Readmission\n",
            "================================================================================\n",
            "\n",
            "üìä LEGAL COMPLIANCE CHECK:\n",
            "   Disparate Impact: 1.000 (PASS ‚úì)\n",
            "   EEOC Threshold: 0.80 - 1.25 (legal range)\n",
            "\n",
            "   ‚úì Within legal compliance\n",
            "\n",
            "üìà DETAILED METRICS:\n",
            "   Statistical Parity: 0.000\n",
            "   Equal Opportunity: 0.000\n",
            "   FPR Difference: 0.000\n",
            "   Accuracy Difference: 0.001\n",
            "\n",
            "üî¢ PREDICTION RATES:\n",
            "   Privileged group: 0.0%\n",
            "   Unprivileged group: 0.0%\n",
            "\n",
            "üë• SAMPLE SIZES:\n",
            "   Privileged: 22,875\n",
            "   Unprivileged: 5,718\n",
            "‚úì Healthcare analysis complete\n",
            "\n",
            "================================================================================\n",
            "SAVING RESULTS\n",
            "================================================================================\n",
            "‚úì Saved: criminal_justice_predictions.csv\n",
            "‚úì Saved: lending_predictions.csv\n",
            "‚úì Saved: healthcare_predictions.csv\n",
            "‚úì Saved: all_domains_predictions.csv\n",
            "‚úì Saved: all_bias_metrics.json\n",
            "‚úì Saved: all_models.pkl\n",
            "\n",
            "================================================================================\n",
            "CROSS-DOMAIN BIAS COMPARISON\n",
            "================================================================================\n",
            "\n",
            "          Domain  Disparate Impact Legal Status  Stat Parity  Equal Opp\n",
            "criminal_justice          1.861623       FAIL ‚úó     0.236252   0.165189\n",
            "         lending          0.401302       FAIL ‚úó    -0.090755  -0.104893\n",
            "      healthcare          1.000000       PASS ‚úì     0.000000   0.000000\n",
            "\n",
            "üìä SUMMARY:\n",
            "   Total domains analyzed: 3\n",
            "   Legal violations found: 2\n",
            "   Compliance rate: 33.3%\n",
            "\n",
            "================================================================================\n",
            "‚úì ANALYSIS COMPLETE - READY FOR DASHBOARD\n",
            "================================================================================\n",
            "\n",
            "NEXT STEP: Run the dashboard with: streamlit run dashboard.py\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}